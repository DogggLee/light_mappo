# light_mappo

Lightweight version of MAPPO to help you quickly migrate to your local environment.

è½»é‡ç‰ˆMAPPOï¼Œå¸®åŠ©ä½ å¿«é€Ÿç§»æ¤åˆ°æœ¬åœ°ç¯å¢ƒã€‚

- [è§†é¢‘è§£æ](https://www.bilibili.com/video/BV1bd4y1L73N/?spm_id_from=333.999.0.0&vd_source=d8ab7686ea514acb6635faa5d2227d61)  

è‹±æ–‡ç¿»è¯‘ç‰ˆreadmeï¼Œè¯·ç‚¹å‡»[è¿™é‡Œ](README.md)

## Table of Contents

- [èƒŒæ™¯](#èƒŒæ™¯)
- [å®‰è£…](#å®‰è£…)
- [ç”¨æ³•](#ç”¨æ³•)

## èƒŒæ™¯

MAPPOåŸç‰ˆä»£ç å¯¹äºç¯å¢ƒçš„å°è£…è¿‡äºå¤æ‚ï¼Œæœ¬é¡¹ç›®ç›´æ¥å°†ç¯å¢ƒå°è£…æŠ½å–å‡ºæ¥ã€‚æ›´åŠ æ–¹ä¾¿å°†MAPPOä»£ç ç§»æ¤åˆ°è‡ªå·±çš„é¡¹ç›®ä¸Šã€‚

## å®‰è£…

ç›´æ¥å°†ä»£ç ä¸‹è½½ä¸‹æ¥ï¼Œåˆ›å»ºä¸€ä¸ªCondaç¯å¢ƒï¼Œç„¶åè¿è¡Œä»£ç ï¼Œç¼ºå•¥è¡¥å•¥åŒ…ã€‚å…·ä½“ä»€ä¹ˆåŒ…ä»¥åå†æ·»åŠ ã€‚

## ç”¨æ³•

- ç¯å¢ƒéƒ¨åˆ†æ˜¯ä¸€ä¸ªç©ºçš„çš„å®ç°ï¼Œæ–‡ä»¶`light_mappo/envs/env_core.py`é‡Œé¢ç¯å¢ƒéƒ¨åˆ†çš„å®ç°ï¼š[Code](https://github.com/tinyzqh/light_mappo/blob/main/envs/env_core.py)

```python
import numpy as np
class EnvCore(object):
    """
    # ç¯å¢ƒä¸­çš„æ™ºèƒ½ä½“
    """
    def __init__(self):
        self.agent_num = 2  # è®¾ç½®æ™ºèƒ½ä½“(å°é£æœº)çš„ä¸ªæ•°ï¼Œè¿™é‡Œè®¾ç½®ä¸ºä¸¤ä¸ª
        self.obs_dim = 14  # è®¾ç½®æ™ºèƒ½ä½“çš„è§‚æµ‹ç»´åº¦
        self.action_dim = 5  # è®¾ç½®æ™ºèƒ½ä½“çš„åŠ¨ä½œç»´åº¦ï¼Œè¿™é‡Œå‡å®šä¸ºä¸€ä¸ªäº”ä¸ªç»´åº¦çš„

    def reset(self):
        """
        # self.agent_numè®¾å®šä¸º2ä¸ªæ™ºèƒ½ä½“æ—¶ï¼Œè¿”å›å€¼ä¸ºä¸€ä¸ªlistï¼Œæ¯ä¸ªlisté‡Œé¢ä¸ºä¸€ä¸ªshape = (self.obs_dim, )çš„è§‚æµ‹æ•°æ®
        """
        sub_agent_obs = []
        for i in range(self.agent_num):
            sub_obs = np.random.random(size=(14, ))
            sub_agent_obs.append(sub_obs)
        return sub_agent_obs

    def step(self, actions):
        """
        # self.agent_numè®¾å®šä¸º2ä¸ªæ™ºèƒ½ä½“æ—¶ï¼Œactionsçš„è¾“å…¥ä¸ºä¸€ä¸ª2çº¬çš„listï¼Œæ¯ä¸ªlisté‡Œé¢ä¸ºä¸€ä¸ªshape = (self.action_dim, )çš„åŠ¨ä½œæ•°æ®
        # é»˜è®¤å‚æ•°æƒ…å†µä¸‹ï¼Œè¾“å…¥ä¸ºä¸€ä¸ªlistï¼Œé‡Œé¢å«æœ‰ä¸¤ä¸ªå…ƒç´ ï¼Œå› ä¸ºåŠ¨ä½œç»´åº¦ä¸º5ï¼Œæ‰€é‡Œæ¯ä¸ªå…ƒç´ shape = (5, )
        """
        sub_agent_obs = []
        sub_agent_reward = []
        sub_agent_done = []
        sub_agent_info = []
        for i in range(self.agent_num):
            sub_agent_obs.append(np.random.random(size=(14,)))
            sub_agent_reward.append([np.random.rand()])
            sub_agent_done.append(False)
            sub_agent_info.append({})

        return [sub_agent_obs, sub_agent_reward, sub_agent_done, sub_agent_info]
```


åªéœ€è¦ç¼–å†™è¿™ä¸€éƒ¨åˆ†çš„ä»£ç ï¼Œå°±å¯ä»¥æ— ç¼è¡”æ¥MAPPOã€‚åœ¨env_core.pyä¹‹åï¼Œå•ç‹¬æå‡ºæ¥äº†ä¸¤ä¸ªæ–‡ä»¶env_discrete.pyå’Œenv_continuous.pyè¿™ä¸¤ä¸ªæ–‡ä»¶ç”¨äºå°è£…å¤„ç†åŠ¨ä½œç©ºé—´å’Œç¦»æ•£åŠ¨ä½œç©ºé—´ã€‚åœ¨algorithms/utils/act.pyä¸­elif self.continuous_action:è¿™ä¸ªåˆ¤æ–­é€»è¾‘ä¹Ÿæ˜¯ç”¨æ¥å¤„ç†è¿ç»­åŠ¨ä½œç©ºé—´çš„ã€‚å’Œrunner/shared/env_runner.pyéƒ¨åˆ†çš„# TODO è¿™é‡Œæ”¹é€ æˆè‡ªå·±ç¯å¢ƒéœ€è¦çš„å½¢å¼å³å¯éƒ½æ˜¯ç”¨æ¥å¤„ç†è¿ç»­åŠ¨ä½œç©ºé—´çš„ã€‚

åœ¨train.pyæ–‡ä»¶é‡Œé¢ï¼Œé€‰æ‹©æ³¨é‡Šè¿ç»­ç¯å¢ƒï¼Œæˆ–è€…ç¦»æ•£ç¯å¢ƒè¿›è¡Œdemoç¯å¢ƒçš„åˆ‡æ¢ã€‚

## Related Efforts

- [on-policy](https://github.com/marlbenchmark/on-policy) - ğŸ’Œ Learn the author implementation of MAPPO.

## Maintainers

[@tinyzqh](https://github.com/tinyzqh).

## License

[MIT](LICENSE) Â© tinyzqh


## éªŒè¯é›†/æµ‹è¯•é›†ï¼ˆScenario Datasetï¼‰

ä¸ºä¿è¯è¯„ä¼°å¯å¤ç°ï¼Œæ¨èæŒ‰ç›®å½•ç»„ç»‡è¯„ä¼°æ•°æ®é›†ï¼š

- `datasets/val/`ï¼šéªŒè¯é›†åœºæ™¯ï¼ˆè°ƒå‚ä¸å›å½’ï¼‰ã€‚
- `datasets/test/`ï¼šæµ‹è¯•é›†åœºæ™¯ï¼ˆæœ€ç»ˆå¯¹æ¯”ï¼‰ã€‚
- `datasets/val/patrol_routes/` ä¸ `datasets/test/patrol_routes/`ï¼šå·¡é€»è·¯å¾„åº“ï¼Œæ¯ä¸ªæ–‡ä»¶ä¸€ä¸ªè·¯å¾„ï¼ˆå»ºè®®æ•°å­—ç¼–å·ï¼‰ã€‚

æ¯ä¸ªåœºæ™¯ä½¿ç”¨**å•ç‹¬çš„ä¸€ä¸ª yaml æ–‡ä»¶**è¡¨ç¤ºï¼Œæ–‡ä»¶åå³åœºæ™¯åç§°ï¼ˆå»ºè®®æ•°å­—ç¼–å·ï¼Œå¦‚ `001.yaml`ã€`002.yaml`ï¼‰ã€‚

æ¯ä¸ªåœºæ™¯æ–‡ä»¶éœ€åŒ…å«å­—æ®µï¼š

- `num_hunters`
- `num_blockers`
- `world_size`
- `dt`
- `capture_radius`
- `capture_steps`
- `episode_length`
- `seed`
- `initial_positions`
- `target_policy_source`
- `target_patrol_route_id`ï¼ˆä»…å¡«å†™å·¡é€»è·¯å¾„åºå·ï¼Œä¾‹å¦‚ `001`ï¼‰
- `target_policy_model_path`ï¼ˆæ–°å¢ï¼šTarget å¤–éƒ¨ç­–ç•¥æ¨¡å‹è·¯å¾„ï¼Œå¯æ”¾åœ¨æ•°æ®é›†ç›®å½•ä¸‹ï¼Œæˆ–æŒ‡å‘è®­ç»ƒè¾“å‡ºæ¨¡å‹ï¼‰
- `eval_target_modes`ï¼ˆå»ºè®®ï¼š`[patrol, train]`ï¼Œç”¨äºåˆ†åˆ«ç»Ÿè®¡ä¸¤ç§ Target æ¨¡å¼ä¸‹çš„å›´æ•æˆåŠŸç‡ï¼‰

åœºæ™¯æ–‡ä»¶ä¸å†ç›´æ¥å†™ `target_patrol_name`ï¼Œè€Œæ˜¯é€šè¿‡ `target_patrol_route_id` å»å¯¹åº”ç›®å½•å†…çš„ `patrol_routes/{idx}.yaml`ã€‚

è¿è¡Œæ—¶å¯ç›´æ¥æŠŠç›®å½•ä¼ ç»™ `--scenario_suite`ï¼š

```bash
python train/train_uav_pursuit.py \
  --config config/minimal_test.yaml \
  --scenario_suite datasets/val
```

è¯„ä¼°é˜¶æ®µä¼šï¼š

1. æŒ‰ç›®å½•ä¸­æ¯ä¸ªåœºæ™¯æ–‡ä»¶é€ä¸ªæ‰§è¡Œï¼›
2. å¯¹ `eval_target_modes` ä¸­çš„æ¯ä¸ªæ¨¡å¼åˆ†åˆ«ç»Ÿè®¡æˆåŠŸç‡ï¼ˆpatrol / trainï¼‰ï¼›
3. å°†ç»“æœè½ç›˜åˆ° `metrics_eval.csv`ï¼ˆå« `scenario_id` å­—æ®µï¼‰ï¼›
4. ä¸ºæ¯ä¸ªåœºæ™¯ä¿å­˜ GIF åˆ° `results/.../run*/eval_gifs/val_{idx}/` ç›®å½•ã€‚



## Related Efforts

- [on-policy](https://github.com/marlbenchmark/on-policy) - ğŸ’Œ Learn the author implementation of MAPPO.

## Maintainers

[@tinyzqh](https://github.com/tinyzqh).

## License

[MIT](LICENSE) Â© tinyzqh
